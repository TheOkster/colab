{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Training your own model with Tensorflow!"
      ],
      "metadata": {
        "id": "V8smNaCo4E5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This exercise will done using Google Colab, Python, and Tensorflow.\n",
        "\n"
      ],
      "metadata": {
        "id": "SsaW3DLi9Oif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please click on the play button below to make sure you have the necessary libraries."
      ],
      "metadata": {
        "id": "PjcY0jZY4UNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "9oNu3KS64TI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5089e7-7e9c-43a2-9396-2172b3de75d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lesson, we'll be classifying movie reviews as negative or positive based off IMDB's dataset! I don't know how many of you have heard of IMDB, but it's a popular movie database website where users can rate movies.\n",
        "\n",
        "Press the button below to download the dataset onto this Colab instance! It won't download to your actual machine.\n",
        "It may take 5s-1m to download."
      ],
      "metadata": {
        "id": "HqxhqPwp5t4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "print(f\"Training Sample Count: {len(x_train)}\")\n",
        "print(f\"Test Sample Count: {len(x_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TjjgoSg6PE3",
        "outputId": "b6cc0137-d15b-4419-aca2-8811e6d3503a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training Sample Count: 25000\n",
            "Test Sample Count: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has been split into train & test subsets.\n",
        "The train subset is used to build up the model. The test subset is not used to make the model directly, but rather to test if it's accurate.\n",
        "\n",
        "You should always have a train & test dataset to make sure your data is accurate. In this case, 50% of the data is used for testing and 50% is used for training."
      ],
      "metadata": {
        "id": "u9L6CR3E9kSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the dataset in a format that Tensorflow can use, we need to play around with the text in the dataset. This command makes sure that no review is more than 256 characters.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0AyvRoA4-jQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pad_sequences(x_train, maxlen=256)\n",
        "x_test = pad_sequences(x_test, maxlen=256)\n"
      ],
      "metadata": {
        "id": "to2NDFk--q8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's actually create the model!"
      ],
      "metadata": {
        "id": "WGO63Oxm_N9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=64, input_length=256),\n",
        "    Flatten(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_hY319W_gAm",
        "outputId": "e474970b-a5f8-4e8b-e564-5df19bd62859"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This might be a bit difficult to understand.\n",
        "When words are input into this model, they aren't actually recognized by the model as words, but numbers. This allows it to more easily group words with similar meaning together e.g. \"mad\" and \"angry\" together to make it easier for the model to recognize.\n",
        "\n",
        "Flatten and Dense are outside of scope of this lesson to explain, but feel feel free to look them up if interested!"
      ],
      "metadata": {
        "id": "f6fKVuEKERjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll train the model using the training data we downloaded earlier! This may take a while. If you want it to go faster, you can decrease the number of epochs (min times it runs through every value in the dataset) but that may affect accuracy!"
      ],
      "metadata": {
        "id": "ox26voqF_sWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=32, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVuou3ua_vLa",
        "outputId": "65a092f2-60d2-4538-f8b5-3d78ecae6337"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - accuracy: 0.6755 - loss: 0.5370 - val_accuracy: 0.8508 - val_loss: 0.3420\n",
            "Epoch 2/4\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 17ms/step - accuracy: 0.9595 - loss: 0.1158 - val_accuracy: 0.8477 - val_loss: 0.3880\n",
            "Epoch 3/4\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9959 - loss: 0.0215 - val_accuracy: 0.8518 - val_loss: 0.4740\n",
            "Epoch 4/4\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.8459 - val_loss: 0.5548\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7acd38e8c410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our model is trained, it's time to see if it can correctly classify our test data!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X52dXFkH_y30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Accuracy: {round(test_accuracy*100, 2)}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5ilrPhp_3Ve",
        "outputId": "e480839e-c011-44a3-b1a0-657c6cc26478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.5449\n",
            "Accuracy: 85.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy will change each time you complete the sequence, but for me it was 85.7% accurate. Not bad!\n",
        "\n",
        "Don't focus on the loss value for now; it measures how well the model's predictions fit their regular values. Unlike accuracy, it isn't a percentage, so don't think of it that way and you can ignore it for the purposes of this exercise."
      ],
      "metadata": {
        "id": "vuiNbR2KA3aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model In Action"
      ],
      "metadata": {
        "id": "5SZ-YgVhBgTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(encoded_review):\n",
        "    return \" \".join([reverse_word_index.get(i - 3, \"?\") for i in encoded_review])\n",
        "\n",
        "def visualize_prediction(review, actual_label, model):\n",
        "    padded_review = pad_sequences([review], maxlen=256)\n",
        "    prediction = model.predict(padded_review)[0][0]\n",
        "    actual_label = \"Positive\" if actual_label == 1 else \"Negative\"\n",
        "    predicted_label = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
        "\n",
        "    print(f\"Review: {decode_review(review)[:257]}{'...' if len(decode_review(review)) > 256 else ''}\")\n",
        "    print(f\"Actual: {actual_label}\")\n",
        "    print(f\"Predicted: {predicted_label}\")\n",
        "    print(f\"Confidence: {round(prediction, 2)*100}% chance it's Positive\")\n",
        "\n",
        "for i in range(5):\n",
        "    visualize_prediction(x_test[i], y_test[i], model)\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM5u6HwbBlj5",
        "outputId": "d42b983e-89d1-4cb2-f25c-3da1a80f0af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Review: ? please give this one a miss br br ? ? and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out...\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "Confidence: 0.0% chance it's Positive\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Review: ? this film requires a lot of patience because it focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances ? the sandy dennis character apartment but the film builds to a disturbing clima...\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Confidence: 100.0% chance it's Positive\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Review: ? many animation buffs consider ? ? the great forgotten genius of one special branch of the art puppet animation which he invented almost single ? and as it happened almost accidentally as a young man ? was more interested in ? than the cinema but his ? att...\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Confidence: 76.99999809265137% chance it's Positive\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "Review: ? i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people ar...\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "Confidence: 37.99999952316284% chance it's Positive\n",
            "\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Review: ? like some other people wrote i'm a die hard mario fan and i loved this game br br this game starts slightly boring but trust me it's worth it as soon as you start your hooked the levels are fun and ? they will hook you ? your mind turns to ? i'm not kiddi...\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Confidence: 100.0% chance it's Positive\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned before, the text is actually processed as numbers rather than words directly. The decode function converts the text back into words so humans can understand it.\n",
        "The confidence represents the percentage the model is sure the prediction is positive."
      ],
      "metadata": {
        "id": "oSBdFfv6DyVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type your own review here and see how the model categorizes it!"
      ],
      "metadata": {
        "id": "suTOHVTVhfIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_custom_text(model, text):\n",
        "    tokens = [word_index.get(word, 2) + 3 for word in text.lower().split()]\n",
        "    padded_tokens = pad_sequences([tokens], maxlen=256)\n",
        "\n",
        "    prediction = model.predict(padded_tokens)[0][0]\n",
        "    predicted_label = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "    print(f\"Confidence: {round(prediction, 2)}% it's Positive\")\n",
        "\n",
        "user_text = input(\"Type your own review: \")\n",
        "predict_custom_text(model, user_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "tPP0KlrrDzb9",
        "outputId": "a2118b99-ba6a-473a-c5bb-bfde1014edb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type your own review: This sucks! I hate Star Wars and anything having to do with it.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-012aeb55e5fb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0muser_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type your own review: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpredict_custom_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}